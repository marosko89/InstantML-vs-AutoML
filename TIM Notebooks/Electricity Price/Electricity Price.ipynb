{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------- Electricity Price -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tim import Tim\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_credentials = json.load(open('tim_credentials.json'))\n",
    "client = Tim(email=tim_credentials['email'],password=tim_credentials['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv('Electricity Price GEFCom 2014.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_input_df = csv_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = 'timestamp'\n",
    "target_variable = 'Price'\n",
    "predictor_candidates = [s for s in list(tim_input_df.columns) if s not in [timestamp,target_variable]]\n",
    "tim_input_df = tim_input_df[[timestamp,target_variable]+predictor_candidates].reset_index(drop=True)\n",
    "tim_input_df[target_variable].iloc[-24:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = tim_input_df\n",
    "fig = plt.subplots.make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig.add_trace(go.Scatter(x=v_data[timestamp], y=v_data[target_variable], name=target_variable), row=1, col=1)\n",
    "for idx, p in enumerate(predictor_candidates):\n",
    "    fig.add_trace(go.Scatter(x=v_data[timestamp], y=v_data[p], name=p), row=2, col=1)\n",
    "fig.update_layout(height=600, width=1200, title_text=\"Data visualization\")\n",
    "fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TIM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTo = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_configuration = {\n",
    "#             \"name\": \"My first forecast job\",\n",
    "#             \"useCase\": {\"id\":\"useCaseId\"},\n",
    "#             \"experiment\": {\"id\":\"experimentId\"},\n",
    "            \"configuration\": {\n",
    "                \"predictionTo\": {\"baseUnit\": \"Sample\",\"value\": predictionTo},\n",
    "#                 \"predictionFrom\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#                 \"modelQuality\": \"Combined\",\n",
    "#                 \"normalization\": True,\n",
    "#                 \"maxModelComplexity\": 50,\n",
    "#                 \"features\": [\n",
    "#                    \"ExponentialMovingAverage\",\n",
    "#                     \"RestOfWeek\",\n",
    "#                     \"Periodic\",\n",
    "#                     \"Intercept\",\n",
    "#                     \"PiecewiseLinear\",\n",
    "#                     \"TimeOffsets\",\n",
    "#                     \"Polynomial\",\n",
    "#                     \"Identity\",\n",
    "#                     \"PublicHolidays\",      \n",
    "# #                     \"SimpleMovingAverage\",\n",
    "# #                     \"Month\",\n",
    "# #                     \"Trend\",\n",
    "# #                     \"DayOfWeek\",\n",
    "# #                     \"Fourier\",\n",
    "#                     ],\n",
    "#                 \"dailyCycle\": False,\n",
    "#                 \"allowOffsets\": True,\n",
    "#                 \"offsetLimit\": {\"type\": \"Explicit\",\"value\": 0},\n",
    "#                 \"memoryLimitCheck\": True,\n",
    "#                  \"predictionIntervals\": 90,\n",
    "#                  \"predictionBoundaries\": {\"type\": \"Explicit\",\n",
    "#                      \"maxValue\": 750,\n",
    "#                     \"minValue\": 100\n",
    "#                      },\n",
    "#                 \"rollingWindow\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#                 \"backtest\": \"All\"\n",
    "                },\n",
    "            \"data\": {\n",
    "#                 \"version\": {\"id\":\"versionId\"},\n",
    "#                 \"inSampleRows\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "                \"outOfSampleRows\": [{\"from\": \"2013-01-01 00:00:00\",\"to\": \"2013-12-16 23:00:00\"}], #{\"baseUnit\": \"Sample\",\"value\": outOfSampleRows} or [{\"from\": \"yyyy-mm-dd HH:MM:SS\",\"to\": \"yyyy-mm-dd HH:MM:SS\"}]\n",
    "#                 \"imputation\": {\"type\": \"Linear\",\"maxGapLength\": 6},\n",
    "#                 \"columns\": [\n",
    "#                     1,\n",
    "#                     3,\n",
    "#                     \"wind\"\n",
    "#                     ],\n",
    "#                 \"targetColumn\": \"y\",\n",
    "#                 \"holidayColumn\": holidayColumn,\n",
    "#                 \"timeScale\": {\"baseUnit\": \"Hour\",\"value\": 1},\n",
    "#                 \"aggregation\": \"Mean\"\n",
    "                }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_job_results_accuracy(response):   \n",
    "    bin_json = response['bin']\n",
    "    bin_accuracy_df = pd.DataFrame()\n",
    "    for n in bin_json:\n",
    "        bin_accuracy_df = bin_accuracy_df.append(pd.DataFrame(n).reset_index().rename(columns={'index':'KPI'}))\n",
    "    bin_accuracy_df['accuracy_type'] = 'bin'\n",
    "\n",
    "    samplesAhead_json = response['samplesAhead']\n",
    "    samplesAhead_accuracy_df = pd.DataFrame()\n",
    "    for n in samplesAhead_json:\n",
    "        samplesAhead_accuracy_df = samplesAhead_accuracy_df.append(pd.DataFrame(n).reset_index().rename(columns={'index':'KPI'}))\n",
    "    samplesAhead_accuracy_df['accuracy_type'] = 'samplesAhead'\n",
    "\n",
    "    all_accuracy_df = pd.DataFrame(response['all']).reset_index().rename(columns={'index':'KPI'})\n",
    "    all_accuracy_df['accuracy_type'] = 'all'\n",
    "    id_columns = ['KPI','name','accuracy_type']\n",
    "    acc_df = all_accuracy_df.append(samplesAhead_accuracy_df).append(bin_accuracy_df)\n",
    "    df = pd.melt(acc_df, id_vars=id_columns, value_vars=list(set(acc_df.columns)-set(id_columns)))\n",
    "    return df\n",
    "\n",
    "def get_forecast_job_results_model(response):\n",
    "    properties = response['model']['modelZoo']['variableProperties']\n",
    "    models = response['model']['modelZoo']['models']\n",
    "    \n",
    "    pi_df = pd.DataFrame(properties).sort_values(by='importance',ascending=False)\n",
    "    pi_df['rel_importance'] = pi_df['importance']/pi_df.sum()['importance']\n",
    "    \n",
    "    features = []\n",
    "    for m in models:\n",
    "        terms = m['terms']\n",
    "        for count,t in enumerate(terms):\n",
    "            f,b = find_feature(t['parts'])\n",
    "            features.append([m['index'],count,f,t['importance'],b])\n",
    "    fi_df = pd.DataFrame(features,columns=['Model','Term','Feature','importance','beta'])\n",
    "    return pi_df,fi_df,models\n",
    "\n",
    "def find_feature(sub_parts):\n",
    "    dow_list = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "    month_list = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "    features_list = []\n",
    "    for c,s in enumerate(sub_parts):\n",
    "        if   s['type']=='β':\n",
    "            sub_feature = ''\n",
    "        elif s['type']=='TimeOffsets':\n",
    "            sub_feature = s['predictor']+'(t'+str(s['offset'])+')'\n",
    "        elif s['type']=='RestOfWeek':\n",
    "            sub_feature ='DoW(t'+str(s['offset'])+') <= '+dow_list[s['day']-1]\n",
    "        elif s['type']=='Intercept':\n",
    "            sub_feature = 'Intercept('+str(int(s['value']))+')'\n",
    "        elif s['type']=='Cos':\n",
    "            sub_feature = 'Cos('+str(int(s['period']))+';'+s['unit']+')'\n",
    "        elif s['type']=='Sin':\n",
    "            sub_feature = 'Sin('+str(int(s['period']))+';'+s['unit']+')'\n",
    "        elif s['type']=='ExponentialMovingAverage':\n",
    "            sub_feature = 'EMA_'+s['predictor']+'(t'+str(int(s['offset']))+'; w='+str(int(s['window']))+')'\n",
    "        elif s['type']=='Identity':\n",
    "            sub_feature = s['predictor']\n",
    "        elif s['type']=='PiecewiseLinear':\n",
    "            sub_feature = 'max(0;'+str(s['subtype'])+'*('+str(round(s['knot'],6))+'-'+s['predictor']+'(t'+str(s['offset'])+')))'\n",
    "        elif s['type']=='SimpleMovingAverage':\n",
    "            sub_feature = 'SMA_'+s['predictor']+'(t'+str(int(s['offset']))+'; w='+str(int(s['window']))+')'\n",
    "        elif s['type']=='Fourier':\n",
    "            sub_feature = 'Fourier('+str(s['period'])+')'\n",
    "        elif s['type']=='Weekday':\n",
    "            sub_feature = 'DoW(t'+str(s['offset'])+') = '+dow_list[s['day']-1]\n",
    "        elif s['type']=='Month':\n",
    "            sub_feature = 'Month<='+month_list[s['month']]\n",
    "        elif s['type']=='PublicHoliday':\n",
    "            sub_feature = s['predictor']\n",
    "        elif s['type']=='Trend':\n",
    "            sub_feature = 'Trend'\n",
    "        else:\n",
    "            sub_feature = '_test_'\n",
    "        if s['type']=='β':\n",
    "            features_list.append(sub_feature)\n",
    "            beta = s['value']\n",
    "        else:\n",
    "            features_list.append(' & '+sub_feature) if c>0 else features_list.append(sub_feature)\n",
    "    feature_output = ''.join(str(e) for e in features_list)\n",
    "    return feature_output,beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_response = client.clean_forecast(dataset = tim_input_df, dataset_configuration = {}, job_configuration = job_configuration, handle_dataset_upload_status_poll = print, handle_forecast_status_poll = print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configuration = {\n",
    "#     \"timestampFormat\": \"yyyy-mm-dd HH:MM:SS.sss\",\n",
    "#     \"timestampColumn\": 1,\n",
    "#     \"decimalSeparator\": \".\",\n",
    "#     \"csvSeparator\": \",\",\n",
    "#     \"timeZone\": \"Z\",\n",
    "#     \"name\": \"Vienna\",\n",
    "#     \"description\": \"Electricity consumption\",\n",
    "#     \"samplingPeriod\": {\n",
    "#         \"baseUnit\": \"Hour\",\n",
    "#         \"value\": 1\n",
    "#     },\n",
    "#     \"workspace\": {\n",
    "#         \"id\": \"ef47117c-5408-4603-9d6f-735f45a74ff3\"\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_response = client.upload_dataset(dataset=tim_input_df,configuration=dataset_configuration,handle_status_poll=print)\n",
    "dataset_id = dataset_response[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_response = client.build_forecasting_model_and_execute(dataset_id=dataset_id,job_configuration=job_configuration,wait_to_finish=True,handle_status_poll=print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_meta_data = forecast_response[0]\n",
    "properties_df,features_df,model = get_forecast_job_results_model(forecast_response[1])\n",
    "forecast_job_results_table_df = forecast_response[2]\n",
    "for i in forecast_job_results_table_df['forecast_type'].unique():\n",
    "    forecast_job_results_table_df.loc[forecast_job_results_table_df['forecast_type']==i, i] = forecast_job_results_table_df['forecast']\n",
    "accuracy_df = get_forecast_job_results_accuracy(forecast_response[3])\n",
    "job_logs_df = pd.DataFrame(forecast_response[4]).sort_values(by='createdAt').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_job_results_table_df['MAE'] = abs(forecast_job_results_table_df['forecast']-forecast_job_results_table_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = forecast_job_results_table_df\n",
    "fig = plt.subplots.make_subplots(rows=2, cols=1, vertical_spacing=0.04,shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['target'], name='Actuals', line=dict(color='black')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['Production'], name='Prediction', line=dict(color='goldenrod')), row=1, col=1)\n",
    "# fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['lower_bound'], name='Lower bound', line=dict(color='lightgrey')), row=1, col=1)\n",
    "# fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['upper_bound'], name='Upper bound', line=dict(color='lightgrey')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['InSample'], name='InSample', line=dict(color='green')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['OutOfSample'], name='OutOfSample', line=dict(color='red')), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['MAE'], name='MAE', line=dict(color='blue')), row=2, col=1)\n",
    "fig.update_layout(height=800, width=1200, title_text=\"Results\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = forecast_job_results_table_df[['target','OutOfSample']].dropna()\n",
    "x_axis = 'target'\n",
    "y_axis = 'OutOfSample'\n",
    "max_x = max(v_data[x_axis].max(),v_data[y_axis].max())\n",
    "min_x = min(v_data[x_axis].min(),v_data[y_axis].min())\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=v_data[x_axis], y=v_data[y_axis],mode='markers',name='results'))\n",
    "fig.add_trace(go.Scatter(x=[min_x,max_x], y=[min_x,max_x],mode='lines',name='y=x'))\n",
    "fig.update_layout(height=500, width=1200, title_text=\"Parity Plot\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = accuracy_df.dropna()['accuracy_type'].unique()\n",
    "columns = accuracy_df.dropna()['KPI'].unique()\n",
    "subplot_titles = []\n",
    "for i in rows:\n",
    "    for j in columns: subplot_titles.append(str(i)+\" \"+str(j))\n",
    "fig = plt.subplots.make_subplots(rows=len(rows), cols=len(columns), vertical_spacing=0.04,subplot_titles=subplot_titles)\n",
    "\n",
    "for r,i in enumerate(rows):\n",
    "    for c,j in enumerate(columns):\n",
    "        v_data = accuracy_df[(accuracy_df['KPI']==j)&(accuracy_df['accuracy_type']==i)].pivot(index=['KPI','name','accuracy_type'], columns='variable', values='value').reset_index()\n",
    "        fig.add_trace(go.Bar(x=v_data['name'], y=v_data['inSample'], name=str(i)+\" \"+str(j),text=round(v_data['inSample'],2),textposition='auto'), row=r+1, col=c+1)\n",
    "        fig.add_trace(go.Bar(x=v_data['name'], y=v_data['outOfSample'], name=str(i)+\" \"+str(j),text=round(v_data['outOfSample'],2),textposition='auto'), row=r+1, col=c+1)\n",
    "fig.update_layout(height=1200, width=1400, title_text=\"Data visualization\",)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_v_df = properties_df[properties_df['importance']>0]\n",
    "x_axis = 'name'\n",
    "y_axis = 'rel_importance'\n",
    "\n",
    "fig1 = go.Figure(go.Bar(x=b_v_df[x_axis], y=b_v_df[y_axis],text=round(b_v_df[y_axis],2),textposition='auto'))\n",
    "fig1.update_layout(height=500,width=1200,title_text='Predictor Importances',xaxis_title=x_axis,yaxis_title=y_axis)\n",
    "print('Predictors not used:'+str(list(properties_df[~(properties_df['importance']>0)]['name'])))\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings = list(job_logs_df[job_logs_df['messageType'] == \"Warning\"]['message'])\n",
    "warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_job_results_table_df.to_csv('forecast_job_results_table_df.csv',index=False)\n",
    "# accuracy_df.to_csv('forecast_job_results_table_df.csv',index=False)\n",
    "# properties_df.to_csv('properties_df.csv',index=False)\n",
    "# features_df.to_csv('features_df.csv',index=False)\n",
    "# job_logs_df.to_csv('job_logs_df.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
